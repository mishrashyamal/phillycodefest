{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "\n",
    "pdf_file = open(\"RISHABH's_RESUME.docx.pdf\", 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "for page_num in range(len(pdf_reader.pages)):\n",
    "    \n",
    "    page = pdf_reader.pages[page_num]\n",
    "    text = page.extract_text()\n",
    "    text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load the en_core_web_sm model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import re\n",
    "\n",
    "# example resume text\n",
    "\n",
    "# create a Spacy Doc object\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find the start and end indices of the work experience section\n",
    "work_exp_start = 0\n",
    "work_exp_end = len(text)\n",
    "for i, token in enumerate(doc):\n",
    "    if token.text.lower() == \"work experience\" or token.text.lower() == \"work\" or token.text.lower() == \"experience\" or token.text.lower() == \"professional experience\" or token.text.lower() == \"relevant experience\":\n",
    "        work_exp_start = token.idx\n",
    "    elif token.text.lower() == \"education\" or token.text.lower() == \"educational background\" or token.text.lower() == \"education background\":\n",
    "        work_exp_end = token.idx\n",
    "        break\n",
    "\n",
    "# Extract the contents of the work experience section\n",
    "work_exp = text[work_exp_start+1:work_exp_end-2]\n",
    "\n",
    "# Find the start and end indices of the project section\n",
    "project_start = work_exp_end\n",
    "project_end = len(text)\n",
    "for i, token in enumerate(doc):\n",
    "    if token.text.lower() == \"projects\" or token.text.lower() == \"project experience\" or token.text.lower() == \"project\":\n",
    "        project_start = token.idx\n",
    "    elif token.text.lower() == \"skills\" or token.text.lower() == \"activities\" or token.text.lower() == \"awards\" or token.text.lower() == \"achievements\":\n",
    "        project_end = token.idx\n",
    "        break\n",
    "\n",
    "work = text[work_exp_start+1:work_exp_end-2]\n",
    "\n",
    "# Extract the contents of the project section\n",
    "project = text[project_start+1:project_end-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def all_words(text):\n",
    "    doc = nlp(text)\n",
    "    # Find the start and end indices of the work experience section\n",
    "    work_exp_start = 0\n",
    "    work_exp_end = len(text)\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text.lower() == \"work experience\" or token.text.lower() == \"work\" or token.text.lower() == \"experience\" or token.text.lower() == \"professional experience\" or token.text.lower() == \"relevant experience\":\n",
    "            work_exp_start = token.idx\n",
    "        elif token.text.lower() == \"education\" or token.text.lower() == \"educational background\" or token.text.lower() == \"education background\":\n",
    "            work_exp_end = token.idx\n",
    "            break\n",
    "    work_exp = text[work_exp_start+1:work_exp_end-2]\n",
    "    # Find the start and end indices of the project section\n",
    "    project_start = work_exp_end\n",
    "    project_end = len(text)\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text.lower() == \"projects\" or token.text.lower() == \"project experience\" or token.text.lower() == \"project\":\n",
    "            project_start = token.idx\n",
    "        elif token.text.lower() == \"skills\" or token.text.lower() == \"activities\" or token.text.lower() == \"awards\" or token.text.lower() == \"achievements\":\n",
    "            project_end = token.idx\n",
    "            break\n",
    "    work = text[work_exp_start+1:work_exp_end-2]\n",
    "    # Extract the contents of the project section\n",
    "    project = text[project_start+1:project_end-2]\n",
    "\n",
    "    work = re.sub(r'[^a-zA-Z0-9]', ' ', work)\n",
    "    project = re.sub(r'[^a-zA-Z0-9]', ' ', project)\n",
    "\n",
    "    work = work.split('\\n')\n",
    "    project = project.split('\\n')\n",
    "\n",
    "    all = work + project\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xperience by gaining insights intocustomers   boosted the accuracy of predicting the demand for 36 products by 40  by applying statistical forecasting using lstm   developed a predictive system to monitor machine performance and downtime with a 94  accuracy rate  leading toa 14  increase in overall equipment effectiveness oee  projects github  philadelphia court sentencing prediction  nov 2022  constructed a multi class classification model that predicted the type of sentencing for a database of over 300 000docket details   achieved an accuracy rate of 81  by employing a deep learning classification model and a 78  accuracy rate usingxgboost mathematical equation solver using nmt mar 2022  interpreted complex mathematical equations as a language and applied neural machine translation using a bi lstmmodel to convert them into their corresponding solutions   expanded a dataset containing more than 400 000 equations and their answers to enhance the training and testingof the model   attained an accuracy of 82  on the validation dataset covid 19 case detection and forecasting  may 2022  used an lstm time series forecasting model to forecast the course of covid 19 cases over the next 30 days with anaccuracy of 84    utilized a convolutional neural network model using greedy pre training to predict whether a specific ct scanincluded signs of covid 19 and attained an accuracy of 98  without overfitting   results were showcased using a website developed using reactjs as the frontend and flask as the backend  achievement swon the social justice hackathon  philadelphia oct  2022won the best major project award at ujjain engineering college  ujjain april 2022won the uec thon ujjain engineering college  ujjain jan  20', '']\n"
     ]
    }
   ],
   "source": [
    "print(all_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
